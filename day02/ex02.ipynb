{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd32b147-6695-480d-87e4-eb8ab3624f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in d:\\mldl\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\mldl\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\mldl\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\mldl\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\mldl\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f23db18-ea6d-40f9-b0c8-0cc5645fdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\")\n",
    "text = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2486dbd0-60f7-405e-9bba-17a76ef6bace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                       Language is never, ever, ever, random\\n\\n                                                               ADAM KILGARRIFF\\n\\n\\n\\n\\nAbstract\\nLanguage users never choose words randomly, and language is essentially\\nnon-random. Statistical hypothesis testing uses a null hypothesis, which\\nposits randomness. Hence, when we look at linguistic phenomena in cor-\\npora, the null hypothesis will never be true. Moreover, where there is enough\\ndata, we shall (almost) always be able to establish '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "159773d8-0564-4198-bf53-c56f047871cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f56251c-863f-4fc2-a97a-062022e8fdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                       Language is never, ever, ever, random\\n\\n                                                               ADAM KILGARRIFF\\n\\n\\n\\n\\nAbstract\\nLanguage users never choose words randomly, and language is essentially\\nnon-random.',\n",
       " 'Statistical hypothesis testing uses a null hypothesis, which\\nposits randomness.',\n",
       " 'Hence, when we look at linguistic phenomena in cor-\\npora, the null hypothesis will never be true.',\n",
       " 'Moreover, where there is enough\\ndata, we shall (almost) always be able to establish that it is not true.',\n",
       " 'In\\ncorpus studies, we frequently do have enough data, so the fact that a rela-\\ntion between two phenomena is demonstrably non-random, does not sup-\\nport the inference that it is not arbitrary.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sent_tokenize(text)\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24a9fd1-d9a0-4cf2-9655-b866155dab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sentence))) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ace4b5f-cab6-44e9-bed1-61378e1f9217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['language',\n",
       "  'is',\n",
       "  'never',\n",
       "  ',',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'random',\n",
       "  'adam',\n",
       "  'kilgarriff',\n",
       "  'abstract',\n",
       "  'language',\n",
       "  'users',\n",
       "  'never',\n",
       "  'choose',\n",
       "  'words',\n",
       "  'randomly',\n",
       "  ',',\n",
       "  'and',\n",
       "  'language',\n",
       "  'is',\n",
       "  'essentially',\n",
       "  'non-random',\n",
       "  '.'],\n",
       " ['statistical',\n",
       "  'hypothesis',\n",
       "  'testing',\n",
       "  'uses',\n",
       "  'a',\n",
       "  'null',\n",
       "  'hypothesis',\n",
       "  ',',\n",
       "  'which',\n",
       "  'posits',\n",
       "  'randomness',\n",
       "  '.'],\n",
       " ['hence',\n",
       "  ',',\n",
       "  'when',\n",
       "  'we',\n",
       "  'look',\n",
       "  'at',\n",
       "  'linguistic',\n",
       "  'phenomena',\n",
       "  'in',\n",
       "  'cor-',\n",
       "  'pora',\n",
       "  ',',\n",
       "  'the',\n",
       "  'null',\n",
       "  'hypothesis',\n",
       "  'will',\n",
       "  'never',\n",
       "  'be',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['moreover',\n",
       "  ',',\n",
       "  'where',\n",
       "  'there',\n",
       "  'is',\n",
       "  'enough',\n",
       "  'data',\n",
       "  ',',\n",
       "  'we',\n",
       "  'shall',\n",
       "  '(',\n",
       "  'almost',\n",
       "  ')',\n",
       "  'always',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'establish',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'true',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'corpus',\n",
       "  'studies',\n",
       "  ',',\n",
       "  'we',\n",
       "  'frequently',\n",
       "  'do',\n",
       "  'have',\n",
       "  'enough',\n",
       "  'data',\n",
       "  ',',\n",
       "  'so',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'a',\n",
       "  'rela-',\n",
       "  'tion',\n",
       "  'between',\n",
       "  'two',\n",
       "  'phenomena',\n",
       "  'is',\n",
       "  'demonstrably',\n",
       "  'non-random',\n",
       "  ',',\n",
       "  'does',\n",
       "  'not',\n",
       "  'sup-',\n",
       "  'port',\n",
       "  'the',\n",
       "  'inference',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'arbitrary',\n",
       "  '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35058abe-8337-4b94-9f50-4790a29437b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d128763-2b84-4e42-8feb-a7803e7027e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, padded_sentences = padded_everygram_pipeline(3, tokenized_text) # train_date - everygram(max_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca11713d-0cb6-4374-9541-d97ffa4dcf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>',),\n",
       " ('<s>', '<s>'),\n",
       " ('<s>', '<s>', 'language'),\n",
       " ('<s>',),\n",
       " ('<s>', 'language'),\n",
       " ('<s>', 'language', 'is'),\n",
       " ('language',),\n",
       " ('language', 'is'),\n",
       " ('language', 'is', 'never'),\n",
       " ('is',),\n",
       " ('is', 'never'),\n",
       " ('is', 'never', ','),\n",
       " ('never',),\n",
       " ('never', ','),\n",
       " ('never', ',', 'ever'),\n",
       " (',',),\n",
       " (',', 'ever'),\n",
       " (',', 'ever', ','),\n",
       " ('ever',),\n",
       " ('ever', ','),\n",
       " ('ever', ',', 'ever'),\n",
       " (',',),\n",
       " (',', 'ever'),\n",
       " (',', 'ever', ','),\n",
       " ('ever',),\n",
       " ('ever', ','),\n",
       " ('ever', ',', 'random'),\n",
       " (',',),\n",
       " (',', 'random'),\n",
       " (',', 'random', 'adam'),\n",
       " ('random',),\n",
       " ('random', 'adam'),\n",
       " ('random', 'adam', 'kilgarriff'),\n",
       " ('adam',),\n",
       " ('adam', 'kilgarriff'),\n",
       " ('adam', 'kilgarriff', 'abstract'),\n",
       " ('kilgarriff',),\n",
       " ('kilgarriff', 'abstract'),\n",
       " ('kilgarriff', 'abstract', 'language'),\n",
       " ('abstract',),\n",
       " ('abstract', 'language'),\n",
       " ('abstract', 'language', 'users'),\n",
       " ('language',),\n",
       " ('language', 'users'),\n",
       " ('language', 'users', 'never'),\n",
       " ('users',),\n",
       " ('users', 'never'),\n",
       " ('users', 'never', 'choose'),\n",
       " ('never',),\n",
       " ('never', 'choose'),\n",
       " ('never', 'choose', 'words'),\n",
       " ('choose',),\n",
       " ('choose', 'words'),\n",
       " ('choose', 'words', 'randomly'),\n",
       " ('words',),\n",
       " ('words', 'randomly'),\n",
       " ('words', 'randomly', ','),\n",
       " ('randomly',),\n",
       " ('randomly', ','),\n",
       " ('randomly', ',', 'and'),\n",
       " (',',),\n",
       " (',', 'and'),\n",
       " (',', 'and', 'language'),\n",
       " ('and',),\n",
       " ('and', 'language'),\n",
       " ('and', 'language', 'is'),\n",
       " ('language',),\n",
       " ('language', 'is'),\n",
       " ('language', 'is', 'essentially'),\n",
       " ('is',),\n",
       " ('is', 'essentially'),\n",
       " ('is', 'essentially', 'non-random'),\n",
       " ('essentially',),\n",
       " ('essentially', 'non-random'),\n",
       " ('essentially', 'non-random', '.'),\n",
       " ('non-random',),\n",
       " ('non-random', '.'),\n",
       " ('non-random', '.', '</s>'),\n",
       " ('.',),\n",
       " ('.', '</s>'),\n",
       " ('.', '</s>', '</s>'),\n",
       " ('</s>',),\n",
       " ('</s>', '</s>'),\n",
       " ('</s>',)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(train_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "444488ce-9627-4ccf-9056-d0a589d94dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'language',\n",
       " 'is',\n",
       " 'never',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'random',\n",
       " 'adam',\n",
       " 'kilgarriff',\n",
       " 'abstract',\n",
       " 'language',\n",
       " 'users',\n",
       " 'never',\n",
       " 'choose',\n",
       " 'words',\n",
       " 'randomly',\n",
       " ',',\n",
       " 'and',\n",
       " 'language',\n",
       " 'is',\n",
       " 'essentially',\n",
       " 'non-random',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'statistical',\n",
       " 'hypothesis',\n",
       " 'testing',\n",
       " 'uses',\n",
       " 'a',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'which',\n",
       " 'posits',\n",
       " 'randomness',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'hence',\n",
       " ',',\n",
       " 'when',\n",
       " 'we',\n",
       " 'look',\n",
       " 'at',\n",
       " 'linguistic',\n",
       " 'phenomena',\n",
       " 'in',\n",
       " 'cor-',\n",
       " 'pora',\n",
       " ',',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'moreover',\n",
       " ',',\n",
       " 'where',\n",
       " 'there',\n",
       " 'is',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'we',\n",
       " 'shall',\n",
       " '(',\n",
       " 'almost',\n",
       " ')',\n",
       " 'always',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'establish',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'in',\n",
       " 'corpus',\n",
       " 'studies',\n",
       " ',',\n",
       " 'we',\n",
       " 'frequently',\n",
       " 'do',\n",
       " 'have',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'a',\n",
       " 'rela-',\n",
       " 'tion',\n",
       " 'between',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " 'is',\n",
       " 'demonstrably',\n",
       " 'non-random',\n",
       " ',',\n",
       " 'does',\n",
       " 'not',\n",
       " 'sup-',\n",
       " 'port',\n",
       " 'the',\n",
       " 'inference',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'present',\n",
       " 'experimental',\n",
       " 'evidence',\n",
       " 'of',\n",
       " 'how',\n",
       " 'arbitrary',\n",
       " 'associations',\n",
       " 'between',\n",
       " 'word',\n",
       " 'frequencies',\n",
       " 'and',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'systematically',\n",
       " 'non-random',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'review',\n",
       " 'literature',\n",
       " 'in',\n",
       " 'which',\n",
       " 'hypothesis',\n",
       " 'test-',\n",
       " 'ing',\n",
       " 'has',\n",
       " 'been',\n",
       " 'used',\n",
       " ',',\n",
       " 'and',\n",
       " 'show',\n",
       " 'how',\n",
       " 'it',\n",
       " 'has',\n",
       " 'often',\n",
       " 'led',\n",
       " 'to',\n",
       " 'unhelpful',\n",
       " 'or',\n",
       " 'mislead-',\n",
       " 'ing',\n",
       " 'results',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'keywords',\n",
       " ':',\n",
       " '쎲쎲쎲',\n",
       " '1',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'introduction',\n",
       " 'any',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " 'might',\n",
       " 'or',\n",
       " 'might',\n",
       " 'not',\n",
       " 'be',\n",
       " 'related',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " 'pos-',\n",
       " 'sibilities',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'association',\n",
       " 'is',\n",
       " 'random',\n",
       " ',',\n",
       " 'arbitrary',\n",
       " ',',\n",
       " 'motivated',\n",
       " 'or',\n",
       " 'pre-',\n",
       " 'dictable',\n",
       " '(',\n",
       " 'r',\n",
       " ',',\n",
       " 'a',\n",
       " ',',\n",
       " 'm',\n",
       " ',',\n",
       " 'p',\n",
       " ')',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'bulk',\n",
       " 'of',\n",
       " 'linguistic',\n",
       " 'questions',\n",
       " 'concern',\n",
       " 'the',\n",
       " 'dis-',\n",
       " 'tinction',\n",
       " 'between',\n",
       " 'a',\n",
       " 'and',\n",
       " 'm.',\n",
       " 'a',\n",
       " 'linguistic',\n",
       " 'account',\n",
       " 'of',\n",
       " 'a',\n",
       " 'phenomenon',\n",
       " 'gen-',\n",
       " 'erally',\n",
       " 'gives',\n",
       " 'us',\n",
       " 'reason',\n",
       " 'to',\n",
       " 'view',\n",
       " 'the',\n",
       " 'relation',\n",
       " 'between',\n",
       " ',',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'a',\n",
       " 'verb',\n",
       " '’',\n",
       " 's',\n",
       " 'syntax',\n",
       " 'and',\n",
       " 'its',\n",
       " 'semantics',\n",
       " ',',\n",
       " 'as',\n",
       " 'motivated',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'arbitrary',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'however',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'in',\n",
       " 'general',\n",
       " 'possible',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'a-m',\n",
       " 'distinction',\n",
       " 'mathematically',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'distinction',\n",
       " 'that',\n",
       " 'can',\n",
       " 'be',\n",
       " 'modeled',\n",
       " 'mathematically',\n",
       " 'is',\n",
       " 'between',\n",
       " 'r',\n",
       " 'and',\n",
       " 'not-r',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " ',',\n",
       " 'between',\n",
       " 'random',\n",
       " ',',\n",
       " 'or',\n",
       " 'uncorrelated',\n",
       " ',',\n",
       " 'pairs',\n",
       " 'and',\n",
       " 'pairs',\n",
       " 'where',\n",
       " 'there',\n",
       " 'is',\n",
       " 'some',\n",
       " 'correlation',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'arbitrary',\n",
       " ',',\n",
       " 'motivated',\n",
       " 'or',\n",
       " 'predictable.1',\n",
       " 'the',\n",
       " 'mechanism',\n",
       " 'here',\n",
       " 'is',\n",
       " 'hypothesis-testing',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'a',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'h0',\n",
       " 'is',\n",
       " 'con-',\n",
       " 'structed',\n",
       " 'to',\n",
       " 'model',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'in',\n",
       " 'which',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'correlation',\n",
       " 'between',\n",
       " 'corpus',\n",
       " 'linguistics',\n",
       " 'and',\n",
       " 'linguistic',\n",
       " 'theory',\n",
       " '1⫺2',\n",
       " '(',\n",
       " '2005',\n",
       " ')',\n",
       " ',',\n",
       " '263⫺275',\n",
       " '1613-7027/05/0001⫺0263',\n",
       " '쑕',\n",
       " 'walter',\n",
       " 'de',\n",
       " 'gruyter',\n",
       " '264',\n",
       " 'a.',\n",
       " 'kilgarriff',\n",
       " 'the',\n",
       " 'two',\n",
       " 'phenomena',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'as',\n",
       " 'the',\n",
       " 'mathematics',\n",
       " 'of',\n",
       " 'the',\n",
       " 'random',\n",
       " 'is',\n",
       " 'well',\n",
       " 'under-',\n",
       " 'stood',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'compute',\n",
       " 'the',\n",
       " 'likelihood',\n",
       " 'of',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'given',\n",
       " 'the',\n",
       " 'data',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'if',\n",
       " 'the',\n",
       " 'likelihood',\n",
       " 'is',\n",
       " 'low',\n",
       " ',',\n",
       " 'we',\n",
       " 'reject',\n",
       " 'h0',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'for',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'is',\n",
       " 'that',\n",
       " 'language',\n",
       " 'is',\n",
       " 'not',\n",
       " 'random',\n",
       " ',',\n",
       " 'so',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'is',\n",
       " 'never',\n",
       " 'true',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'language',\n",
       " 'is',\n",
       " 'not',\n",
       " 'random',\n",
       " 'because',\n",
       " 'we',\n",
       " 'speak',\n",
       " 'or',\n",
       " 'write',\n",
       " 'with',\n",
       " 'purposes',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " ',',\n",
       " 'indeed',\n",
       " ',',\n",
       " 'without',\n",
       " 'computational',\n",
       " 'help',\n",
       " 'are',\n",
       " 'not',\n",
       " 'capable',\n",
       " 'of',\n",
       " ',',\n",
       " 'producing',\n",
       " 'words',\n",
       " 'or',\n",
       " 'sounds',\n",
       " 'or',\n",
       " 'sentences',\n",
       " 'or',\n",
       " 'documents',\n",
       " 'randomly',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'we',\n",
       " 'do',\n",
       " 'not',\n",
       " 'always',\n",
       " 'have',\n",
       " 'enough',\n",
       " 'data',\n",
       " 'to',\n",
       " 'reject',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " ',',\n",
       " 'but',\n",
       " 'that',\n",
       " 'is',\n",
       " 'a',\n",
       " 'distinct',\n",
       " 'issue',\n",
       " ':',\n",
       " 'wherever',\n",
       " 'there',\n",
       " 'is',\n",
       " 'enough',\n",
       " 'data',\n",
       " ',',\n",
       " 'it',\n",
       " 'is',\n",
       " 'rejected',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'using',\n",
       " 'language',\n",
       " 'corpora',\n",
       " ',',\n",
       " 'we',\n",
       " 'are',\n",
       " 'frequently',\n",
       " 'in',\n",
       " 'the',\n",
       " 'fortunate',\n",
       " 'position',\n",
       " 'of',\n",
       " 'having',\n",
       " 'very',\n",
       " 'large',\n",
       " 'quantities',\n",
       " 'of',\n",
       " 'data',\n",
       " 'at',\n",
       " 'our',\n",
       " 'disposal',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'then',\n",
       " ',',\n",
       " 'even',\n",
       " 'where',\n",
       " 'pairs',\n",
       " 'of',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'set',\n",
       " 'up',\n",
       " 'to',\n",
       " 'be',\n",
       " 'linguistically',\n",
       " 'identical',\n",
       " ',',\n",
       " 'the',\n",
       " 'null',\n",
       " 'hypothesis',\n",
       " 'is',\n",
       " 'resoundingly',\n",
       " 'defeated',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'in',\n",
       " 'section',\n",
       " '4',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'an',\n",
       " 'experiment',\n",
       " 'demonstrating',\n",
       " 'this',\n",
       " 'counterintuitive',\n",
       " 'effect',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'there',\n",
       " 'are',\n",
       " 'a',\n",
       " 'number',\n",
       " 'of',\n",
       " 'papers',\n",
       " 'in',\n",
       " 'the',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'literature',\n",
       " 'where',\n",
       " 'researchers',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'testing',\n",
       " 'whether',\n",
       " 'an',\n",
       " 'association',\n",
       " 'was',\n",
       " 'lin-',\n",
       " 'guistically',\n",
       " 'salient',\n",
       " ',',\n",
       " 'or',\n",
       " 'used',\n",
       " 'the',\n",
       " 'confidence',\n",
       " 'with',\n",
       " 'which',\n",
       " 'h0',\n",
       " 'could',\n",
       " 'be',\n",
       " 're-',\n",
       " 'jected',\n",
       " 'as',\n",
       " 'a',\n",
       " 'measure',\n",
       " 'of',\n",
       " 'salience',\n",
       " ',',\n",
       " 'whereas',\n",
       " 'in',\n",
       " 'fact',\n",
       " 'they',\n",
       " 'were',\n",
       " 'merely',\n",
       " 'testing',\n",
       " 'whether',\n",
       " 'they',\n",
       " 'had',\n",
       " 'enough',\n",
       " 'data',\n",
       " 'to',\n",
       " 'reject',\n",
       " 'h0',\n",
       " 'with',\n",
       " 'confidence',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'some',\n",
       " 'such',\n",
       " 'cases',\n",
       " 'are',\n",
       " 'reviewed',\n",
       " 'in',\n",
       " 'section',\n",
       " '5',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'hypothesis',\n",
       " 'testing',\n",
       " 'has',\n",
       " 'been',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'the',\n",
       " 'acquisition',\n",
       " 'of',\n",
       " 'subcategorization',\n",
       " 'frames',\n",
       " 'from',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'this',\n",
       " 'literature',\n",
       " 'is',\n",
       " 'considered',\n",
       " 'in',\n",
       " 'some',\n",
       " 'detail',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'alternatives',\n",
       " 'to',\n",
       " 'inappropriate',\n",
       " 'hy-',\n",
       " 'pothesis-testing',\n",
       " 'are',\n",
       " 'presented',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'before',\n",
       " 'proceeding',\n",
       " ',',\n",
       " 'may',\n",
       " 'i',\n",
       " 'clarify',\n",
       " 'that',\n",
       " 'this',\n",
       " 'paper',\n",
       " 'is',\n",
       " 'in',\n",
       " 'no',\n",
       " 'way',\n",
       " 'critical',\n",
       " 'of',\n",
       " 'using',\n",
       " 'probability',\n",
       " 'models',\n",
       " ',',\n",
       " 'all',\n",
       " 'of',\n",
       " 'which',\n",
       " 'are',\n",
       " 'based',\n",
       " 'on',\n",
       " 'assumptions',\n",
       " 'of',\n",
       " 'randomness',\n",
       " ',',\n",
       " 'in',\n",
       " 'empirical',\n",
       " 'linguistics',\n",
       " 'in',\n",
       " 'general',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'probability',\n",
       " 'models',\n",
       " 'have',\n",
       " 'been',\n",
       " 'responsible',\n",
       " 'for',\n",
       " 'a',\n",
       " 'large',\n",
       " 'share',\n",
       " 'of',\n",
       " 'progress',\n",
       " 'in',\n",
       " 'the',\n",
       " 'field',\n",
       " 'in',\n",
       " 'the',\n",
       " 'last',\n",
       " 'decade',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'randomness',\n",
       " 'assumptions',\n",
       " 'are',\n",
       " 'always',\n",
       " 'untrue',\n",
       " ',',\n",
       " 'but',\n",
       " 'that',\n",
       " 'does',\n",
       " 'not',\n",
       " 'preclude',\n",
       " 'them',\n",
       " 'from',\n",
       " 'frequently',\n",
       " 'being',\n",
       " 'useful',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'making',\n",
       " 'false',\n",
       " 'assumptions',\n",
       " 'is',\n",
       " 'often',\n",
       " 'an',\n",
       " 'ingenious',\n",
       " 'way',\n",
       " 'to',\n",
       " 'proceed',\n",
       " ';',\n",
       " 'the',\n",
       " 'problem',\n",
       " 'arises',\n",
       " 'where',\n",
       " 'the',\n",
       " 'literal',\n",
       " 'falsity',\n",
       " 'of',\n",
       " 'the',\n",
       " 'assumption',\n",
       " 'is',\n",
       " 'overlooked',\n",
       " ',',\n",
       " 'and',\n",
       " 'inappropri-',\n",
       " 'ate',\n",
       " 'inferences',\n",
       " 'are',\n",
       " 'drawn',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " '2',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'arbitrary',\n",
       " 'and',\n",
       " 'the',\n",
       " 'random',\n",
       " 'in',\n",
       " 'common',\n",
       " 'parlance',\n",
       " ',',\n",
       " 'random',\n",
       " 'and',\n",
       " 'arbitrary',\n",
       " 'are',\n",
       " 'synonyms',\n",
       " ',',\n",
       " 'with',\n",
       " 'diction-',\n",
       " 'aries',\n",
       " 'giving',\n",
       " 'near-identical',\n",
       " 'definitions',\n",
       " ':',\n",
       " 'ldoce',\n",
       " '(',\n",
       " '1995',\n",
       " ')',\n",
       " 'defines',\n",
       " 'random',\n",
       " 'as',\n",
       " 'happening',\n",
       " 'or',\n",
       " 'chosen',\n",
       " 'without',\n",
       " 'any',\n",
       " 'definite',\n",
       " 'plan',\n",
       " ',',\n",
       " 'or',\n",
       " 'pattern',\n",
       " 'and',\n",
       " 'arbitrary',\n",
       " 'as',\n",
       " '1',\n",
       " 'decided',\n",
       " 'or',\n",
       " 'arranged',\n",
       " 'without',\n",
       " 'any',\n",
       " 'reason',\n",
       " 'or',\n",
       " 'plan',\n",
       " ',',\n",
       " 'often',\n",
       " 'unfairly',\n",
       " '…',\n",
       " '2',\n",
       " 'happening',\n",
       " 'or',\n",
       " 'decided',\n",
       " 'by',\n",
       " 'chance',\n",
       " 'rather',\n",
       " 'than',\n",
       " 'a',\n",
       " 'plan',\n",
       " 'language',\n",
       " 'is',\n",
       " 'never',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'ever',\n",
       " ',',\n",
       " 'random',\n",
       " '265',\n",
       " 'superficially',\n",
       " ',',\n",
       " 'randomness',\n",
       " ',',\n",
       " 'as',\n",
       " 'defined',\n",
       " 'here',\n",
       " ',',\n",
       " 'is',\n",
       " 'what',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'sense',\n",
       " 'of',\n",
       " 'random',\n",
       " 'captures',\n",
       " 'and',\n",
       " 'makes',\n",
       " 'explicit',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'the',\n",
       " 'technical',\n",
       " 'sense',\n",
       " 'is',\n",
       " 'defined',\n",
       " 'in',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'statistical',\n",
       " 'independence',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<s>',\n",
       " 'first',\n",
       " ',',\n",
       " 'we',\n",
       " 'formalize',\n",
       " 'the',\n",
       " 'framework',\n",
       " ':',\n",
       " 'for',\n",
       " 'a',\n",
       " 'population',\n",
       " 'of',\n",
       " 'events',\n",
       " ',',\n",
       " 'the',\n",
       " 'first',\n",
       " 'phenomenon',\n",
       " 'holds',\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c9e17ab-0238-4e82-ac24-c14e00d2fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLE(Maximum Likelihood Extimation)\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "033c2277-e56a-4680-bab3-f3ad60a1c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLE(3) # 3-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99f5341a-645f-476d-870f-5004c77f93f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "694cd29f-98b5-4a36-8d90-fbaca6ae73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e01cef2-8f09-41b3-aef5-37f062b10c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1391"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab)\n",
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "793a4684-db2c-43b1-8821-ccc7fe8894a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.score()\n",
    "model.score(\"is\", [\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca3b9765-20e5-44c8-bb61-944ada5449d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"never\", [\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc5fcca9-e362-4251-9b8c-f3767e1c5f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(\"never\", [\"language\", \"is\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "164d76eb-27e4-4bd9-a024-cf0be0a758e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = list(model.vocab)\n",
    "recommends = []\n",
    "for word in vocabs:\n",
    "    score = model.score(word, [\"language\", \"is\"])\n",
    "    if score >= 0.5:\n",
    "        recommends.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d6207dc-9098-430c-9f0c-546a343a3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5305bcfe-336e-4eb6-bf1c-b9c221ce9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.generate(토큰 갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52b50b7c-e5b4-4869-886a-1c3cc4cf6b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['events',\n",
       " 'where',\n",
       " 'y',\n",
       " 'does',\n",
       " 'not',\n",
       " 'preclude',\n",
       " 'them',\n",
       " 'from',\n",
       " 'frequently',\n",
       " 'being',\n",
       " 'useful',\n",
       " '.',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>',\n",
       " '</s>']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "539b8234-a438-4c80-91ca-cfd7d090e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08892ed1-37c9-42f8-9f37-232eb2a17f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detokenize = TreebankWordDetokenizer().detokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e71c324a-f4ad-4523-92a7-ae277f2b8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genrate_sentence(model, token_count):\n",
    "    sentences = model.generate(token_count)\n",
    "    content = []\n",
    "    for word in sentences:\n",
    "        if word == '<s>':\n",
    "            continue\n",
    "        if word == '</s>':\n",
    "            break\n",
    "        content.append(word)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f46428e-9078-41cc-93db-be4b155e4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples being random samples drawn from the claws-5 tagset as used in'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genrate_sentence(model, 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
